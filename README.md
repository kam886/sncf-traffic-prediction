
# Pr√©diction du nombre de validations en gare SNCF-Transilien

Projet r√©alis√© dans le cadre d‚Äôun **data challenge acad√©mique** en 2024.

---

## üéØ Objectif

Anticiper √† moyen et long terme le nombre de validations de titres de transport (passages par portiques) dans les gares SNCF-Transilien en √éle-de-France.
Ce projet vise √† am√©liorer la performance du service en pr√©voyant l'affluence quotidienne par gare.

---

## üìÇ Donn√©es

* `train.csv` : 1 237 971 lignes ‚Äì validations quotidiennes pour 448 gares du r√©seau Transilien de janvier 2015 √† d√©cembre 2022
* `test.csv` : 78 652 lignes ‚Äì m√™mes gares, de janvier √† juin 2023 (√† pr√©dire)
* Variables :

  * `date` : date au format YYYY-MM-DD
  * `station` : identifiant anonymis√© de la gare
  * `y` : nombre de validations
  * `job` : 1 si jour ouvrable standard, 0 sinon
  * `ferie` : 1 si jour f√©ri√©
  * `vacances` : 1 si vacances scolaires


**Remarque :** Les donn√©es peuvent √™tre t√©l√©charg√©es [https://challengedata.ens.fr/].
---

## Technologies et librairies utilis√©es

* **Python**
* **Jupyter Notebook**
* `pandas`, `numpy` : manipulation des donn√©es
* `matplotlib`, `seaborn` : visualisation
* `scikit-learn` : mod√®les de r√©gression classiques
* `XGBoost` : boosting performant
* `TensorFlow / Keras` : r√©seau de neurones (exp√©rimental)

---

## Approche

1. **Exploration des donn√©es**

   * Analyse temporelle par station
   * Visualisation des tendances annuelles, mensuelles et hebdomadaires

2. **Feature Engineering**

   * Cr√©ation de nouvelles variables (jour de la semaine, week-end, etc.)
   * Ajout d‚Äôindicateurs contextuels : vacances scolaires, jours f√©ri√©s, jours ouvrables

3. **Pr√©traitement des donn√©es**

   * Fusion des jeux `X_train` et `Y_train` via une cl√© combinant la date et la station (`date_station`)
   * Encodage des identifiants de gares avec `LabelEncoder`
   * Nettoyage des dates (suppression des tirets, conversion en cha√Æne de caract√®res)
   * Transformation logarithmique de la cible (`log1p(y)`) pour r√©duire l‚Äôimpact des valeurs extr√™mes

4. **Mod√©lisation**

   * Entra√Ænement de plusieurs mod√®les sur les donn√©es de 2015 √† 2022
   * Pr√©diction sur la p√©riode janvier‚Äìjuin 2023
    

5. **√âvaluation**

   * M√©trique utilis√©e : **MAPE** (Mean Absolute Percentage Error)
   * R√©sultats compar√©s √† un benchmark fourni par le challenge

---

## Mod√®les test√©s

* ExtraTreesRegressor
* ExtraTreeRegressor
* LinearRegression
* RidgeRegression
* DecisionTreeRegressor
* RandomForestRegressor
* BaggingRegressor
* GradientBoostingRegressor
* XGBoost
* R√©seau de neurones simple (Keras)

---

## R√©sultats

* Les performances varient selon les mod√®les et les gares
* XGBoost et RandomForest ont montr√© les meilleurs r√©sultats en termes de MAPE global
* La transformation logarithmique a am√©lior√© la stabilit√© des pr√©dictions sur les gares √† fort trafic
* Le r√©seau de neurones a √©t√© test√© √† titre exploratoire et n‚Äôa pas surpass√© les mod√®les classiques



